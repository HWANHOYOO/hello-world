2019빅콘테스트 서브웨이팀(Innovation 분야)
=======================


## PART1 환경 데이터 전처리
* * *
- *환경전처리1단계(종로구).py*와 *환경전처리1단계(노원구).py*파일을 사용하여 진행한다. 
1. BigDataContest의 Eco_jongRo파일에 있는 종로구 환경지수 측정 데이터를 for문을 통해, 읽어온다.
2. flag 실외 구분을 나타내는 지표가 -999(음수)를 나타낼 때, 단말기 데이터가 모두 동일한 값으로 확인 되기 때문에, 제거한다.
3. flag가 1일 때, 전체 데이터는 양수를 나타내며, 정상적인 값으로 측정되기 때문에, 다음 조건에 해당하는 데이터만 가지고 온다.
4. 열에서 co2와 vocs값은 -9999 혹은 -999로 구성되기 때문에, 전체 데이터값이 동일하고 의미없는 데이터라 판단되어 제거한다. 
5. pm10,pm25는 미세먼지의 농도 지수이기 때문에, 음의 값을 가질 수 없으므로, 음의 값을 가질 경우, nan값으로 대체한다.(이후 동 단위로 묶어서 동의 평균을 낼때, 전체 동 평균에 해당 값이 고려되지 않도록 nan값으로 대체한다.)
6. noise는 음수를 가질 수 없으므로 음수값을 가질 경우, nan값으로 대체한다.
7. temp의 경우, 한국의 최고기온 40도, 최저기온 -32도임을 고려하여, -40이하 혹은 50이상인 값에 대해서는 이상치로 판단되어 nan값으로 대체한다.
8. humi의 경우, 측정값이 음수가 될 수 없기 때문에, 음수를 nan갑승로 대체한다. 


## PART2 데이터 병합
* * *
- *환경전처리2단계(종로구).py*와 *환경전처리1단계(노원구).py*파일을 사용하여 진행한다. 
1.  BigDataContest의 JongRo파일에 있는 데이터(전처리1단계가 적용된 파일)를 읽어온다.
2.  index를 datetime형식을 이용하여, 일 단위로 통합한다. 이때, 같은 일자의 경우 데이터의 값을 평균내서 통합했다.

-*환경전처리3단계(구 별로 묶기)*파일을 사용하여 진행한다.
1. '노원구_환경'파일에 있는 'Final_'로 시작하는 모든 파일을 'testcsv.csv'파일에 저장한다.(*종로구도 방법은 동일하다*)
2. 'testcsv.csv'파일의 데이터를 tm기준으로 그룹화한다.
3. 인덱스(tm)을 기준으로 평균을 낸다.
4. '구별 묶음'폴더에 결과 값을 csv파일로 저장한다.

-(동별로 묶기)
1. 주최 측에서 제공한 '04_Innovation 분야_환경기상데이터(케이웨더)_데이터정의서(행정동추가)' 정보를 기반으로 
관측기의 데이터를 동 별 파일로 분류하였다.
2. *환경전처리3단계 코드를 각 파일 별로 실행*시켜 동 별 데이터를 구하였다.

- 환경전처리4단계 (빈 곳 채우기)
1. '노원구' list.txt의 리스트를 열고 파일 이름을 리스트에 저장한다.
2. '노원구'파일 안의 csv파일을 읽어온다.
3. Nowon_Combined(일별).csv파일을 읽어온다.
4. nan값을 9999로 치환한다.
5. 9000 이상의 값은 Nowon_Combined(일별).csv 파일에서 값을 가져온다.
6. 이 과정을 pm10, pm25, humi, noise, temp 파일에 반복하여 실행한다.
7. 결과를 '동별관측기(일별, 빈곳 채움)' 파일에 저장한다.

## PART3 중회귀 분석(카드매출)
* * *
- 환경데이터와 카드매출데이터
1. 환경데이터 평균에서 3시그마 이상, 이하 값을 이상치로 판단, 이상치 데이터를 3시그마 경계값으로 대체 -> 'hwan_code.py' 파일의 std_based_outlier(df) 함수
2. 카드매출데이터를 업종 별(23개)로 나누어 따로 저장 -> 'Card_Spend_csv_Convert.py', '업종별카드매출'
3. 업종 별 카드매출데이터를 코드 상에서 성 별(2개), 20대 부터 10년 단위 세대 별(5개), 동 별(25개)로 나눔 -> 'hwan_code.py'
4. 나눈 카드매출데이터을 종속변수, 동별 환경데이터를 독립변수로 하여 중회귀분석 실시 -> 'hwan_code.py'
5. 회귀식을 구성하는 데이터의 개수가 약 30여개 이상, R^2 0.35 이상, Durbin_Watson 1.5~2.5, Jarque_Bera 6 미만인 데이터 추출 
6. pm10 변수의 p-value가 0.05 미만인 회귀식은 좋음 판단, pm10 변수의 p-value가 0.05이상인 회귀식 중 R^2가 비교적 높은 회귀식은 보통 판단 -> '환경_카드매출중회귀.xlsx'

## PART4 중회귀 분석(GS유통 데이터)
* * *
- 환경데이터와 유통데이터(GS리테일)
1. 카드매출데이터와 동일한 방식으로 중회귀 분석을 돌리면 회귀식 잔차의 정규분포 여부를 알려주는 Jarque_Bera 지표가 매우 큰 값을 가진다. 이는 잔차가 정규분포를 따르지 않음을 나타내므로 회귀식의 기본 가정을 위배한다.
2. 회귀식에 들어가는 독립변수와 종속변수를 모두 정규분포를 따르게 log변환하였다. 
3. 기존 std_based_outlier(df) 함수는 3시그마 밖의 이상치를 경계값으로 바꾸는 역할을 하였지만, 이 분석에서는 이상치를 제거하는 std_based_outlier1(df) 함수를 이용하였다.
4. 독립변수는 환경데이터의 온도,습도,미세먼지,소음이고 GS데이터의 각 품목별 항목을 종속변수로 삼아 중회귀분석을 실행하였다. -> 'reg_GS.py', '동별GS.csv'
5. 회귀식을 구성하는 데이터의 개수가 100개 이상, R^2 0.35 이상, Durbin_Watson 1.5~2.5, Jarque_Bera 6 미만인 데이터 추출
6. 추출된 회귀분석 중 p-value가 0.05이상인 변수를 풀링하여 다시 회귀분석을 진행하였다. -> 'reg_GS_one.py', 'GS간추린거.xlsx'
7. pm10 이 풀링되지 않고 adj_R^2가 0.35 이상인 회귀분석은 좋음 판단, pm10이 풀링된 회귀분석 중 adj_R^2가 약 0.7인 경우나 pm10이 풀링되지 않았지만 adj_R^2가 0.35 미만인 경우 보통 판단, pm10이 풀링되고 adj_R^2가 0.35 미만인 분석은 나쁨 판단을 하였다. 'GS간추린거.xlsx'


